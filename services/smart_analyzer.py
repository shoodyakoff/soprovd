"""
Smart Analyzer v6.0 - –ß–∏—Å—Ç–∞—è –≤–µ—Ä—Å–∏—è
–¢–æ–ª—å–∫–æ —Ä–∞–±–æ—á–∞—è –ª–æ–≥–∏–∫–∞ –±–µ–∑ legacy –∫–æ–¥–∞

–ê–†–•–ò–¢–ï–ö–¢–£–†–ê:
1. –ê–Ω–∞–ª–∏–∑ –≤–∞–∫–∞–Ω—Å–∏–∏ (—Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π)
2. –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—é–º–µ (—Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π) 
3. –ê–Ω–∞–ª–∏–∑ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π (—Ç–æ—á–Ω—ã–µ –º–∞—Ç—á–∏)
4. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–∏—Å—å–º–∞ (—Å–≤—è–∑–Ω–∞—è –∏—Å—Ç–æ—Ä–∏—è)
5. –î–µ-–ò–ò-—Ñ–∏–∫–∞—Ü–∏—è (—É–±–∏—Ä–∞–µ–º —à—Ç–∞–º–ø—ã)

–ü–£–ë–õ–ò–ß–ù–´–ï –§–£–ù–ö–¶–ò–ò:
- analyze_and_generate_with_analysis() - –æ—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–æ–¥–∞–∫—à–Ω–∞
"""

import json
import logging
from typing import Dict, Any, Optional

from utils.prompts import (
    VACANCY_ANALYSIS_PROMPT,
    RESUME_ANALYSIS_PROMPT, 
    MATCHING_ANALYSIS_PROMPT,
    LETTER_GENERATION_PROMPT,
    DEAI_PROMPT
)

logger = logging.getLogger(__name__)


class SmartAnalyzer:
    """–£–º–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä v6.0 - —Ç–æ–ª—å–∫–æ —Ä–∞–±–æ—á–∞—è –ª–æ–≥–∏–∫–∞"""
    
    def __init__(self, openai_service):
        self.openai = openai_service
    
    async def generate_full_analysis_and_letter(
        self,
        vacancy_text: str,
        resume_text: str,
        style: str = "professional"
    ) -> Dict[str, str]:
        """
        –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥: 4-—ç—Ç–∞–ø–Ω—ã–π –∞–Ω–∞–ª–∏–∑ + –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–∏—Å—å–º–∞
        
        Returns:
            Dict —Å –ø–∏—Å—å–º–æ–º –∏ –∞–Ω–∞–ª–∏–∑–æ–º: {'letter': str, 'analysis': str}
        """
        logger.info("üöÄ –ó–∞–ø—É—Å–∫–∞—é 4-—ç—Ç–∞–ø–Ω—ã–π –∞–Ω–∞–ª–∏–∑ v6.0...")
        logger.info(f"üìä –í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: –≤–∞–∫–∞–Ω—Å–∏—è={len(vacancy_text)} —Å–∏–º–≤–æ–ª–æ–≤, —Ä–µ–∑—é–º–µ={len(resume_text)} —Å–∏–º–≤–æ–ª–æ–≤")
        
        # –≠–¢–ê–ü 1: –ê–Ω–∞–ª–∏–∑ –≤–∞–∫–∞–Ω—Å–∏–∏
        logger.info("üîç –≠–¢–ê–ü 1: –ê–Ω–∞–ª–∏–∑ –≤–∞–∫–∞–Ω—Å–∏–∏...")
        vacancy_analysis = await self._analyze_vacancy(vacancy_text)
        logger.info("‚úÖ –≠–¢–ê–ü 1 –∑–∞–≤–µ—Ä—à–µ–Ω")
        
        # –≠–¢–ê–ü 2: –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—é–º–µ  
        logger.info("üë§ –≠–¢–ê–ü 2: –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—é–º–µ...")
        resume_analysis = await self._analyze_resume(resume_text)
        logger.info("‚úÖ –≠–¢–ê–ü 2 –∑–∞–≤–µ—Ä—à–µ–Ω")
        
        # –≠–¢–ê–ü 3: –ê–Ω–∞–ª–∏–∑ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
        logger.info("‚ö° –≠–¢–ê–ü 3: –ê–Ω–∞–ª–∏–∑ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π...")
        matching_analysis = await self._analyze_matching(vacancy_analysis, resume_analysis)
        logger.info("‚úÖ –≠–¢–ê–ü 3 –∑–∞–≤–µ—Ä—à–µ–Ω")
        
        # –≠–¢–ê–ü 4: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–∏—Å—å–º–∞
        logger.info("‚úçÔ∏è –≠–¢–ê–ü 4: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–∏—Å—å–º–∞...")
        letter = await self._generate_letter(matching_analysis)
        logger.info(f"‚úÖ –≠–¢–ê–ü 4 –∑–∞–≤–µ—Ä—à–µ–Ω. –î–ª–∏–Ω–∞ –ø–∏—Å—å–º–∞: {len(letter)} —Å–∏–º–≤–æ–ª–æ–≤")
        
        # –≠–¢–ê–ü 5: –î–µ-–ò–ò-—Ñ–∏–∫–∞—Ü–∏—è
        logger.info("üîß –≠–¢–ê–ü 5: –î–µ-–ò–ò-—Ñ–∏–∫–∞—Ü–∏—è...")
        final_letter = await self._deai_text(letter)
        logger.info(f"‚úÖ –≠–¢–ê–ü 5 –∑–∞–≤–µ—Ä—à–µ–Ω. –§–∏–Ω–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞: {len(final_letter)} —Å–∏–º–≤–æ–ª–æ–≤")
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∞–Ω–∞–ª–∏–∑ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        formatted_analysis = self._format_analysis(matching_analysis)
        
        logger.info("üéâ 4-—ç—Ç–∞–ø–Ω—ã–π –∞–Ω–∞–ª–∏–∑ v6.0 –∑–∞–≤–µ—Ä—à–µ–Ω!")
        return {
            'letter': final_letter,
            'analysis': formatted_analysis
        }
    
    # ============ –ü–†–ò–í–ê–¢–ù–´–ï –ú–ï–¢–û–î–´ –≠–¢–ê–ü–û–í ============
    
    async def _analyze_vacancy(self, vacancy_text: str) -> Dict[str, Any]:
        """–≠–¢–ê–ü 1: –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –≤–∞–∫–∞–Ω—Å–∏–∏"""
        prompt = VACANCY_ANALYSIS_PROMPT.format(vacancy_text=vacancy_text)
        
        try:
            response = await self.openai.get_completion(
                prompt=prompt,
                temperature=0.3,
                max_tokens=2000
            )
            
            if not response:
                logger.error("‚ùå –ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –≤–∞–∫–∞–Ω—Å–∏–∏")
                return self._fallback_vacancy()
            
            return self._parse_json(response, "vacancy")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –≤–∞–∫–∞–Ω—Å–∏–∏: {e}")
            return self._fallback_vacancy()
    
    async def _analyze_resume(self, resume_text: str) -> Dict[str, Any]:
        """–≠–¢–ê–ü 2: –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ä–µ–∑—é–º–µ"""
        prompt = RESUME_ANALYSIS_PROMPT.format(resume_text=resume_text)
        
        try:
            response = await self.openai.get_completion(
                prompt=prompt,
                temperature=0.3,
                max_tokens=2000
            )
            
            if not response:
                logger.error("‚ùå –ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —Ä–µ–∑—é–º–µ")
                return self._fallback_resume()
            
            return self._parse_json(response, "resume")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ä–µ–∑—é–º–µ: {e}")
            return self._fallback_resume()
    
    async def _analyze_matching(
        self, 
        vacancy_analysis: Dict[str, Any], 
        resume_analysis: Dict[str, Any]
    ) -> Dict[str, Any]:
        """–≠–¢–ê–ü 3: –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π"""
        prompt = MATCHING_ANALYSIS_PROMPT.format(
            vacancy_analysis=json.dumps(vacancy_analysis, ensure_ascii=False, indent=2),
            resume_analysis=json.dumps(resume_analysis, ensure_ascii=False, indent=2)
        )
        
        try:
            response = await self.openai.get_completion(
                prompt=prompt,
                temperature=0.4,
                max_tokens=2000
            )
            
            if not response:
                logger.error("‚ùå –ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π")
                return self._fallback_matching()
            
            return self._parse_json(response, "matching")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π: {e}")
            return self._fallback_matching()
    
    async def _generate_letter(self, matching_analysis: Dict[str, Any]) -> str:
        """–≠–¢–ê–ü 4: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–∏—Å—å–º–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞"""
        prompt = LETTER_GENERATION_PROMPT.format(
            matching_analysis=json.dumps(matching_analysis, ensure_ascii=False, indent=2)
        )
        
        try:
            response = await self.openai.get_completion(
                prompt=prompt,
                temperature=0.7,
                max_tokens=1500
            )
            
            if not response:
                logger.error("‚ùå –ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–∏—Å—å–º–∞")
                raise Exception("–ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç GPT")
            
            return response.strip()
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–∏—Å—å–º–∞: {e}")
            raise
    
    async def _deai_text(self, text: str) -> str:
        """–≠–¢–ê–ü 5: –î–µ-–ò–ò-—Ñ–∏–∫–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞"""
        prompt = DEAI_PROMPT.format(text=text)
        
        try:
            response = await self.openai.get_completion(
                prompt=prompt,
                temperature=0.5,
                max_tokens=1500
            )
            
            if not response:
                logger.warning("‚ùå –ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –ø—Ä–∏ –¥–µ-–ò–ò-—Ñ–∏–∫–∞—Ü–∏–∏, –≤–æ–∑–≤—Ä–∞—â–∞—é –∏—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç")
                return text
            
            return response.strip()
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –¥–µ-–ò–ò-—Ñ–∏–∫–∞—Ü–∏–∏: {e}")
            return text  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç –ø—Ä–∏ –æ—à–∏–±–∫–µ
    
    # ============ –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –ú–ï–¢–û–î–´ ============
    
    def _parse_json(self, response: str, stage: str) -> Dict[str, Any]:
        """–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ JSON –æ—Ç–≤–µ—Ç–∞"""
        try:
            # –û—á–∏—â–∞–µ–º –æ—Ç markdown –±–ª–æ–∫–æ–≤
            cleaned = response.strip()
            if cleaned.startswith('```json'):
                cleaned = cleaned[7:]
            if cleaned.endswith('```'):
                cleaned = cleaned[:-3]
            cleaned = cleaned.strip()
            
            parsed = json.loads(cleaned)
            logger.info(f"‚úÖ JSON —É—Å–ø–µ—à–Ω–æ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω –¥–ª—è {stage}")
            return parsed
            
        except json.JSONDecodeError as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ JSON –¥–ª—è {stage}: {e}")
            logger.error(f"–û—Ç–≤–µ—Ç: {response[:200]}...")
            
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º fallback
            if stage == "vacancy":
                return self._fallback_vacancy()
            elif stage == "resume":
                return self._fallback_resume()
            elif stage == "matching":
                return self._fallback_matching()
            else:
                return {}
    
    def _format_analysis(self, matching_analysis: Dict[str, Any]) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        try:
            summary = "üìä –ê–ù–ê–õ–ò–ó –°–û–í–ü–ê–î–ï–ù–ò–ô –í–ê–ö–ê–ù–°–ò–ò –ò –†–ï–ó–Æ–ú–ï\n\n"
            
            # –ü—Ä—è–º—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
            exact_matches = matching_analysis.get('exact_matches', [])
            if exact_matches:
                summary += "‚úÖ –ü–†–Ø–ú–´–ï –°–û–í–ü–ê–î–ï–ù–ò–Ø:\n"
                for match in exact_matches[:5]:
                    req = match.get('vacancy_requirement', '–¢—Ä–µ–±–æ–≤–∞–Ω–∏–µ')
                    evidence = match.get('evidence', '–û–ø—ã—Ç –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω')
                    summary += f"‚Ä¢ {req} ‚Üí {evidence}\n"
                summary += "\n"
            
            # –°–∏–ª—å–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
            strong_matches = matching_analysis.get('strong_matches', [])
            if strong_matches:
                summary += "‚ö° –°–ò–õ–¨–ù–´–ï –°–û–í–ü–ê–î–ï–ù–ò–Ø:\n"
                for match in strong_matches[:3]:
                    req = match.get('vacancy_requirement', '–¢—Ä–µ–±–æ–≤–∞–Ω–∏–µ')
                    evidence = match.get('evidence', '–°–º–µ–∂–Ω—ã–π –æ–ø—ã—Ç')
                    summary += f"‚Ä¢ {req} ‚Üí {evidence}\n"
                summary += "\n"
            
            # –ü—Ä–æ–±–µ–ª—ã
            gaps = matching_analysis.get('critical_gaps', [])
            if gaps:
                summary += "‚ö†Ô∏è –û–ë–õ–ê–°–¢–ò –î–õ–Ø –†–ê–ó–í–ò–¢–ò–Ø:\n"
                for gap in gaps[:3]:
                    if isinstance(gap, dict):
                        summary += f"‚Ä¢ {gap.get('missing_requirement', '–ü—Ä–æ–±–µ–ª –≤ –Ω–∞–≤—ã–∫–∞—Ö')}\n"
                    else:
                        summary += f"‚Ä¢ {gap}\n"
                summary += "\n"
            
            # –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞
            advantages = matching_analysis.get('unique_advantages', [])
            if advantages:
                summary += "üéØ –£–ù–ò–ö–ê–õ–¨–ù–´–ï –ü–†–ï–ò–ú–£–©–ï–°–¢–í–ê:\n"
                for advantage in advantages[:3]:
                    if isinstance(advantage, dict):
                        summary += f"‚Ä¢ {advantage.get('advantage', '–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ü–µ–Ω–Ω–æ—Å—Ç—å')}\n"
                    else:
                        summary += f"‚Ä¢ {advantage}\n"
            
            return summary
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∞–Ω–∞–ª–∏–∑–∞: {e}")
            return "üìä –ê–Ω–∞–ª–∏–∑ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –≤—ã–ø–æ–ª–Ω–µ–Ω, –Ω–æ –≤–æ–∑–Ω–∏–∫–ª–∞ –æ—à–∏–±–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è."
    
    # ============ FALLBACK –î–ê–ù–ù–´–ï ============
    
    def _fallback_vacancy(self) -> Dict[str, Any]:
        """Fallback –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –≤–∞–∫–∞–Ω—Å–∏–∏"""
        return {
            "hard_requirements": [
                {
                    "requirement": "–ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –æ–ø—ã—Ç",
                    "importance": "high",
                    "specificity": "general",
                    "keywords": ["–æ–ø—ã—Ç", "–Ω–∞–≤—ã–∫–∏"]
                }
            ],
            "soft_requirements": [
                {
                    "requirement": "–∫–æ–º–º—É–Ω–∏–∫–∞—Ç–∏–≤–Ω—ã–µ –Ω–∞–≤—ã–∫–∏",
                    "importance": "medium",
                    "specificity": "general",
                    "keywords": ["–∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏—è"]
                }
            ],
            "business_tasks": ["–≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã—Ö –∑–∞–¥–∞—á"],
            "company_context": {
                "size": "—Å—Ä–µ–¥–Ω—è—è –∫–æ–º–ø–∞–Ω–∏—è",
                "industry": "—Ä–∞–∑–ª–∏—á–Ω—ã–µ –æ—Ç—Ä–∞—Å–ª–∏",
                "culture": "–ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–∞—è"
            },
            "key_terms": ["–æ–ø—ã—Ç", "–Ω–∞–≤—ã–∫–∏", "–ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª–∏–∑–º"]
        }
    
    def _fallback_resume(self) -> Dict[str, Any]:
        """Fallback –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ä–µ–∑—é–º–µ"""
        return {
            "technical_skills": [
                {
                    "skill": "–ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–µ –Ω–∞–≤—ã–∫–∏",
                    "level": "intermediate",
                    "context": "—Ä–∞–±–æ—á–∞—è –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç—å",
                    "results": "—É—Å–ø–µ—à–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–¥–∞—á",
                    "keywords": ["–Ω–∞–≤—ã–∫–∏", "–æ–ø—ã—Ç"]
                }
            ],
            "experience": ["–ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –æ–ø—ã—Ç —Ä–∞–±–æ—Ç—ã"],
            "achievements": ["–≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —Ä–∞–±–æ—á–∏—Ö –∑–∞–¥–∞—á"],
            "education": ["–ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ–µ –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ"],
            "additional": ["–¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏"]
        }
    
    def _fallback_matching(self) -> Dict[str, Any]:
        """Fallback –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π"""
        return {
            "exact_matches": [
                {
                    "vacancy_requirement": "–ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –æ–ø—ã—Ç",
                    "resume_match": "–∏–º–µ–µ—Ç—Å—è –æ–ø—ã—Ç —Ä–∞–±–æ—Ç—ã",
                    "evidence": "–ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç—Å—è —Ä–µ–∑—é–º–µ",
                    "relevance_score": 0.95,
                    "bridge_explanation": "–æ–ø—ã—Ç –ø—Ä–∏–º–µ–Ω–∏–º –∫ –Ω–æ–≤–æ–π —Ä–æ–ª–∏"
                }
            ],
            "strong_matches": [
                {
                    "vacancy_requirement": "–ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–µ –Ω–∞–≤—ã–∫–∏",
                    "resume_match": "—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏",
                    "evidence": "–æ–ø–∏—Å–∞–Ω–æ –≤ —Ä–µ–∑—é–º–µ",
                    "relevance_score": 0.8,
                    "bridge_explanation": "–Ω–∞–≤—ã–∫–∏ –ø–µ—Ä–µ–Ω–æ—Å–∏–º—ã"
                }
            ],
            "weak_matches": [],
            "critical_gaps": [],
            "unique_advantages": ["–ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–∞—è —ç–∫—Å–ø–µ—Ä—Ç–∏–∑–∞"]
        }


# ============ –ì–õ–û–ë–ê–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò ============

# –ï–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä
_analyzer_instance: Optional[SmartAnalyzer] = None


def _get_analyzer(openai_service=None) -> SmartAnalyzer:
    """–ü–æ–ª—É—á–∏—Ç—å –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞"""
    global _analyzer_instance
    
    if _analyzer_instance is None:
        if openai_service is None:
            from services.openai_service import openai_service as default_service
            openai_service = default_service
        _analyzer_instance = SmartAnalyzer(openai_service)
    
    return _analyzer_instance


async def analyze_and_generate_with_analysis(
    vacancy_text: str,
    resume_text: str,
    style: str = "professional",
    openai_service=None
) -> Dict[str, str]:
    """
    –ï–î–ò–ù–°–¢–í–ï–ù–ù–ê–Ø –ü–£–ë–õ–ò–ß–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø –¥–ª—è –ø—Ä–æ–¥–∞–∫—à–Ω–∞
    
    Args:
        vacancy_text: –¢–µ–∫—Å—Ç –≤–∞–∫–∞–Ω—Å–∏–∏
        resume_text: –¢–µ–∫—Å—Ç —Ä–µ–∑—é–º–µ  
        style: –°—Ç–∏–ª—å –ø–∏—Å—å–º–∞ (–Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è, –æ—Å—Ç–∞–≤–ª–µ–Ω –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
        openai_service: –°–µ—Ä–≤–∏—Å OpenAI (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        
    Returns:
        Dict —Å –ø–∏—Å—å–º–æ–º –∏ –∞–Ω–∞–ª–∏–∑–æ–º: {'letter': str, 'analysis': str}
    """
    analyzer = _get_analyzer(openai_service)
    return await analyzer.generate_full_analysis_and_letter(vacancy_text, resume_text, style) 