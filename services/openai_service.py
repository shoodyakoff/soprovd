"""
–°–µ—Ä–≤–∏—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å OpenAI API
"""
import asyncio
import logging
import time
from typing import Optional
from openai import AsyncOpenAI
from .ai_service import AIService
from config import (
    OPENAI_API_KEY, 
    OPENAI_MODEL, 
    OPENAI_FALLBACK_MODEL,
    OPENAI_TIMEOUT,
    MAX_GENERATION_ATTEMPTS,
    MIN_RESPONSE_LENGTH,
    OPENAI_TEMPERATURE,
    OPENAI_TOP_P,
    OPENAI_PRESENCE_PENALTY,
    OPENAI_FREQUENCY_PENALTY
)
# –°—Ç–∞—Ä—ã–π –∏–º–ø–æ—Ä—Ç —É–¥–∞–ª–µ–Ω - –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è smart_analyzer_v6.py —Å –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–º–∏ –ø—Ä–æ–º–ø—Ç–∞–º–∏

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logger = logging.getLogger(__name__)

class OpenAIService(AIService):
    """–°–µ—Ä–≤–∏—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å OpenAI API"""
    
    def __init__(self):
        self.client = AsyncOpenAI(api_key=OPENAI_API_KEY)
        self._stats_callback = None
    
    def set_stats_callback(self, callback):
        """–£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å callback –¥–ª—è —Å–±–æ—Ä–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
        self._stats_callback = callback
    
    async def test_api_connection(self) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ä–∞–±–æ—Ç—É OpenAI API
        
        Returns:
            True –µ—Å–ª–∏ API —Ä–∞–±–æ—Ç–∞–µ—Ç, False –≤ –ø—Ä–æ—Ç–∏–≤–Ω–æ–º —Å–ª—É—á–∞–µ
        """
        try:
            logger.info("–ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ OpenAI API...")
            
            response = await asyncio.wait_for(
                self.client.chat.completions.create(
                    model=OPENAI_MODEL,
                    messages=[
                        {
                            "role": "user",
                            "content": "–ü—Ä–∏–≤–µ—Ç! –≠—Ç–æ —Ç–µ—Å—Ç. –û—Ç–≤–µ—Ç—å –æ–¥–Ω–∏–º —Å–ª–æ–≤–æ–º: —Ä–∞–±–æ—Ç–∞—é"
                        }
                    ],
                    max_tokens=10,
                    temperature=0.1
                ),
                timeout=30
            )
            
            if response.choices and response.choices[0].message.content:
                logger.info("‚úÖ OpenAI API —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–æ—Ä–º–∞–ª—å–Ω–æ")
                return True
            else:
                logger.error("‚ùå OpenAI API –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç")
                return False
                
        except asyncio.TimeoutError:
            logger.error("‚ùå –¢–∞–π–º–∞—É—Ç –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ OpenAI API")
            return False
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ OpenAI API: {e}")
            
            # –ü–æ–ø—Ä–æ–±—É–µ–º fallback –º–æ–¥–µ–ª—å
            try:
                logger.info("–ü—Ä–æ–±—É–µ–º fallback –º–æ–¥–µ–ª—å...")
                response = await asyncio.wait_for(
                    self.client.chat.completions.create(
                        model=OPENAI_FALLBACK_MODEL,
                        messages=[
                            {
                                "role": "user",
                                "content": "–¢–µ—Å—Ç"
                            }
                        ],
                        max_tokens=5,
                        temperature=0.1
                    ),
                    timeout=30
                )
                
                if response.choices and response.choices[0].message.content:
                    logger.info(f"‚úÖ Fallback –º–æ–¥–µ–ª—å {OPENAI_FALLBACK_MODEL} —Ä–∞–±–æ—Ç–∞–µ—Ç")
                    return True
                else:
                    logger.error("‚ùå Fallback –º–æ–¥–µ–ª—å –Ω–µ –æ—Ç–≤–µ—á–∞–µ—Ç")
                    return False
                    
            except Exception as fallback_e:
                logger.error(f"‚ùå Fallback –º–æ–¥–µ–ª—å —Ç–æ–∂–µ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç: {fallback_e}")
                return False

    async def _make_openai_request(self, prompt: str) -> Optional[str]:
        """
        –í—ã–ø–æ–ª–Ω—è–µ—Ç –∑–∞–ø—Ä–æ—Å –∫ OpenAI API
        
        Args:
            prompt: –ü—Ä–æ–º–ø—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
            
        Returns:
            –û—Ç–≤–µ—Ç –æ—Ç OpenAI –∏–ª–∏ None –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
        """
        try:
            # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –æ—Å–Ω–æ–≤–Ω—É—é –º–æ–¥–µ–ª—å
            response = await self.client.chat.completions.create(
                model=OPENAI_MODEL,
                messages=[
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                max_tokens=1500,
                temperature=OPENAI_TEMPERATURE,
                top_p=OPENAI_TOP_P,
                presence_penalty=OPENAI_PRESENCE_PENALTY,
                frequency_penalty=OPENAI_FREQUENCY_PENALTY
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ —Å –º–æ–¥–µ–ª—å—é {OPENAI_MODEL}: {e}")
            
            # –ü—Ä–æ–±—É–µ–º fallback –º–æ–¥–µ–ª—å
            try:
                response = await self.client.chat.completions.create(
                    model=OPENAI_FALLBACK_MODEL,
                    messages=[
                        {
                            "role": "user",
                            "content": prompt
                        }
                    ],
                    max_tokens=1500,
                    temperature=OPENAI_TEMPERATURE,
                    top_p=OPENAI_TOP_P,
                    presence_penalty=OPENAI_PRESENCE_PENALTY,
                    frequency_penalty=OPENAI_FREQUENCY_PENALTY
                )
                
                return response.choices[0].message.content
                
            except Exception as fallback_e:
                logger.error(f"–û—à–∏–±–∫–∞ —Å fallback –º–æ–¥–µ–ª—å—é {OPENAI_FALLBACK_MODEL}: {fallback_e}")
                return None
    
    def _is_response_complete(self, response: str) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –æ—Ç–≤–µ—Ç –ø–æ–ª–Ω—ã–º
        
        Args:
            response: –û—Ç–≤–µ—Ç –æ—Ç OpenAI
            
        Returns:
            True –µ—Å–ª–∏ –æ—Ç–≤–µ—Ç –∫–∞–∂–µ—Ç—Å—è –ø–æ–ª–Ω—ã–º
        """
        if not response or len(response.strip()) < MIN_RESPONSE_LENGTH:
            logger.warning(f"–û—Ç–≤–µ—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π: {len(response.strip()) if response else 0} < {MIN_RESPONSE_LENGTH}")
            return False
        
        response = response.strip()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –æ–∫–æ–Ω—á–∞–Ω–∏—è –ø–∏—Å—å–º–∞
        valid_endings = [
            # –û–±—ã—á–Ω—ã–µ –∑–Ω–∞–∫–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è
            '.', '!', '?',
            # –ü–æ–¥–ø–∏—Å–∏ –≤ –ø–∏—Å—å–º–∞—Ö
            '[–í–∞—à–µ –∏–º—è]', '[–í–∞—à–µ –ò–º—è]', '[–ò–º—è]', '[–≤–∞—à–µ –∏–º—è]',
            # –î—Ä—É–≥–∏–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –ø–æ–¥–ø–∏—Å–∏
            '—É–≤–∞–∂–µ–Ω–∏–µ–º', '–±–ª–∞–≥–æ–¥–∞—Ä–Ω–æ—Å—Ç—å—é', '–Ω–∞–¥–µ–∂–¥–æ–π'
        ]
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è –ª–∏ –æ—Ç–≤–µ—Ç –æ–¥–Ω–∏–º –∏–∑ –¥–æ–ø—É—Å—Ç–∏–º—ã—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤
        for ending in valid_endings:
            if response.endswith(ending):
                return True
                
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ - –µ—Å–ª–∏ –ø–∏—Å—å–º–æ —Å–æ–¥–µ—Ä–∂–∏—Ç "–° —É–≤–∞–∂–µ–Ω–∏–µ–º" –≤ –∫–æ–Ω—Ü–µ
        if '—É–≤–∞–∂–µ–Ω–∏–µ–º' in response[-100:] or '–±–ª–∞–≥–æ–¥–∞—Ä–Ω–æ—Å—Ç—å—é' in response[-100:]:
            return True
            
        logger.warning(f"–û—Ç–≤–µ—Ç –Ω–µ –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ: '{response[-50:]}'")
        return False 

    async def get_completion(
        self, 
        prompt: str, 
        temperature: float = 0.7, 
        max_tokens: int = 1500,
        user_id: Optional[int] = None,
        session_id: Optional[str] = None,
        request_type: str = "completion"
    ) -> Optional[str]:
        """
        –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –æ—Ç–≤–µ—Ç–∞ –æ—Ç GPT
        
        Args:
            prompt: –ü—Ä–æ–º–ø—Ç –¥–ª—è GPT
            temperature: –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
            max_tokens: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∏
            session_id: ID —Å–µ—Å—Å–∏–∏ –¥–ª—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∏
            request_type: –¢–∏–ø –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∏
            
        Returns:
            –û—Ç–≤–µ—Ç –æ—Ç GPT –∏–ª–∏ None –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
        """
        start_time = time.time()
        used_model = OPENAI_MODEL
        
        try:
            logger.info(f"ü§ñ –û—Ç–ø—Ä–∞–≤–ª—è—é –∑–∞–ø—Ä–æ—Å –∫ GPT (temp={temperature}, max_tokens={max_tokens}, timeout={OPENAI_TIMEOUT}s)")
            logger.info(f"üìù –î–ª–∏–Ω–∞ –ø—Ä–æ–º–ø—Ç–∞: {len(prompt)} —Å–∏–º–≤–æ–ª–æ–≤")
            
            response = await asyncio.wait_for(
                self.client.chat.completions.create(
                    model=OPENAI_MODEL,
                    messages=[
                        {
                            "role": "user",
                            "content": prompt
                        }
                    ],
                    max_tokens=max_tokens,
                    temperature=temperature
                ),
                timeout=OPENAI_TIMEOUT
            )
            
            response_time_ms = int((time.time() - start_time) * 1000)
            
            if response.choices and response.choices[0].message.content:
                content = response.choices[0].message.content
                logger.info(f"‚úÖ –ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –æ—Ç GPT: {len(content)} —Å–∏–º–≤–æ–ª–æ–≤")
                
                # üìä –ê–ù–ê–õ–ò–¢–ò–ö–ê: –õ–æ–≥–∏—Ä—É–µ–º —É—Å–ø–µ—à–Ω—ã–π –∑–∞–ø—Ä–æ—Å
                await self._log_openai_request(
                    model=used_model,
                    request_type=request_type,
                    prompt_tokens=response.usage.prompt_tokens if response.usage else 0,
                    completion_tokens=response.usage.completion_tokens if response.usage else 0,
                    total_tokens=response.usage.total_tokens if response.usage else 0,
                    response_time_ms=response_time_ms,
                    success=True,
                    user_id=user_id,
                    session_id=session_id
                )
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å callback)
                if hasattr(self, '_stats_callback') and self._stats_callback:
                    self._stats_callback(
                        model=used_model,
                        tokens=response.usage.total_tokens if response.usage else 0
                    )
                
                return content
            else:
                logger.error("‚ùå GPT –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç")
                # üìä –ê–ù–ê–õ–ò–¢–ò–ö–ê: –õ–æ–≥–∏—Ä—É–µ–º –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç
                await self._log_openai_request(
                    model=used_model,
                    request_type=request_type,
                    prompt_tokens=0,
                    completion_tokens=0,
                    total_tokens=0,
                    response_time_ms=response_time_ms,
                    success=False,
                    user_id=user_id,
                    session_id=session_id,
                    error_message="Empty response"
                )
                return None
                
        except asyncio.TimeoutError:
            logger.error("‚ùå –¢–∞–π–º–∞—É—Ç –∑–∞–ø—Ä–æ—Å–∞ –∫ GPT")
            # üìä –ê–ù–ê–õ–ò–¢–ò–ö–ê: –õ–æ–≥–∏—Ä—É–µ–º —Ç–∞–π–º–∞—É—Ç
            await self._log_openai_request(
                model=used_model,
                request_type=request_type,
                prompt_tokens=0,
                completion_tokens=0,
                total_tokens=0,
                response_time_ms=response_time_ms,
                success=False,
                user_id=user_id,
                session_id=session_id,
                error_message="Timeout"
            )
            return None
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ GPT: {e}")
            
            # üìä –ê–ù–ê–õ–ò–¢–ò–ö–ê: –õ–æ–≥–∏—Ä—É–µ–º –æ—à–∏–±–∫—É –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
            try:
                import traceback
                from models.analytics_models import ErrorData
                from services.analytics_service import AnalyticsService
                
                error_data = ErrorData(
                    error_type=type(e).__name__,
                    error_message=str(e),
                    user_id=user_id,
                    session_id=session_id,
                    stack_trace=traceback.format_exc(),
                    handler_name='openai_get_completion'
                )
                analytics = AnalyticsService()
                await analytics.log_error(error_data)
            except Exception as log_error:
                logger.error(f"Failed to log OpenAI error to database: {log_error}")
            
            # –ü—Ä–æ–±—É–µ–º fallback –º–æ–¥–µ–ª—å
            try:
                logger.info(f"üîÑ –ü—Ä–æ–±—É—é fallback –º–æ–¥–µ–ª—å {OPENAI_FALLBACK_MODEL}...")
                response = await asyncio.wait_for(
                    self.client.chat.completions.create(
                        model=OPENAI_FALLBACK_MODEL,
                        messages=[
                            {
                                "role": "user",
                                "content": prompt
                            }
                        ],
                        max_tokens=max_tokens,
                        temperature=temperature
                    ),
                    timeout=OPENAI_TIMEOUT
                )
                
                if response.choices and response.choices[0].message.content:
                    content = response.choices[0].message.content
                    logger.info(f"‚úÖ Fallback –º–æ–¥–µ–ª—å –æ—Ç–≤–µ—Ç–∏–ª–∞: {len(content)} —Å–∏–º–≤–æ–ª–æ–≤")
                    return content
                else:
                    logger.error("‚ùå Fallback –º–æ–¥–µ–ª—å –≤–µ—Ä–Ω—É–ª–∞ –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç")
                    return None
                    
            except Exception as fallback_e:
                logger.error(f"‚ùå Fallback –º–æ–¥–µ–ª—å —Ç–æ–∂–µ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç: {fallback_e}")
                return None

    async def generate_personalized_letter(self, prompt: str, temperature: Optional[float] = None) -> Optional[str]:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø–∏—Å—å–º–æ –ø–æ –≥–æ—Ç–æ–≤–æ–º—É –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–º—É –ø—Ä–æ–º–ø—Ç—É
        
        Args:
            prompt: –ì–æ—Ç–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
            temperature: –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å)
            
        Returns:
            –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –ø–∏—Å—å–º–æ –∏–ª–∏ None –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
        """
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–¥–∞–Ω–Ω—É—é —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É –∏–ª–∏ –±–µ—Ä–µ–º –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        temp = temperature if temperature is not None else OPENAI_TEMPERATURE
        
        # –ü—Ä–æ–±—É–µ–º —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø–∏—Å—å–º–æ —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏
        for attempt in range(MAX_GENERATION_ATTEMPTS):
            try:
                logger.info(f"–ü–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è #{attempt + 1} (temp={temp})")
                
                response = await asyncio.wait_for(
                    self._make_personalized_request(prompt, temp),
                    timeout=OPENAI_TIMEOUT
                )
                
                if response and self._is_response_complete(response):
                    logger.info("–£—Å–ø–µ—à–Ω–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –ø–∏—Å—å–º–æ")
                    return response
                else:
                    logger.warning(f"–ù–µ–ø–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ –ø–æ–ø—ã—Ç–∫–µ #{attempt + 1}")
                    
            except asyncio.TimeoutError:
                logger.error(f"–¢–∞–π–º–∞—É—Ç –Ω–∞ –ø–æ–ø—ã—Ç–∫–µ #{attempt + 1}")
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –Ω–∞ –ø–æ–ø—ã—Ç–∫–µ #{attempt + 1}: {e}")
            
        logger.error("–í—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –Ω–µ—É—Å–ø–µ—à–Ω—ã")
        return None

    async def _make_personalized_request(self, prompt: str, temperature: float) -> Optional[str]:
        """
        –í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å –∫ OpenAI API
        
        Args:
            prompt: –ü—Ä–æ–º–ø—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
            temperature: –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
            
        Returns:
            –û—Ç–≤–µ—Ç –æ—Ç OpenAI –∏–ª–∏ None –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
        """
        try:
            # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –æ—Å–Ω–æ–≤–Ω—É—é –º–æ–¥–µ–ª—å
            response = await self.client.chat.completions.create(
                model=OPENAI_MODEL,
                messages=[
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                max_tokens=1500,
                temperature=temperature,
                top_p=OPENAI_TOP_P,
                presence_penalty=OPENAI_PRESENCE_PENALTY,
                frequency_penalty=OPENAI_FREQUENCY_PENALTY
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ —Å –º–æ–¥–µ–ª—å—é {OPENAI_MODEL}: {e}")
            
            # –ü—Ä–æ–±—É–µ–º fallback –º–æ–¥–µ–ª—å
            try:
                response = await self.client.chat.completions.create(
                    model=OPENAI_FALLBACK_MODEL,
                    messages=[
                        {
                            "role": "user",
                            "content": prompt
                        }
                    ],
                    max_tokens=1500,
                    temperature=temperature,
                    top_p=OPENAI_TOP_P,
                    presence_penalty=OPENAI_PRESENCE_PENALTY,
                    frequency_penalty=OPENAI_FREQUENCY_PENALTY
                )
                
                return response.choices[0].message.content
                
            except Exception as fallback_e:
                logger.error(f"–û—à–∏–±–∫–∞ —Å fallback –º–æ–¥–µ–ª—å—é {OPENAI_FALLBACK_MODEL}: {fallback_e}")
                return None

    async def _log_openai_request(
        self,
        model: str,
        request_type: str,
        prompt_tokens: int,
        completion_tokens: int,
        total_tokens: int,
        response_time_ms: int,
        success: bool,
        user_id: Optional[int] = None,
        session_id: Optional[str] = None,
        error_message: Optional[str] = None
    ) -> None:
        """
        –õ–æ–≥–∏—Ä—É–µ—Ç –∑–∞–ø—Ä–æ—Å –∫ OpenAI –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
        """
        try:
            # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∑–¥–µ—Å—å —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å —Ü–∏–∫–ª–∏—á–µ—Å–∫–∏—Ö –∏–º–ø–æ—Ä—Ç–æ–≤
            from services.analytics_service import AnalyticsService
            from models.analytics_models import OpenAIRequestData
            
            request_data = OpenAIRequestData(
                model=model,
                request_type=request_type,
                prompt_tokens=prompt_tokens,
                completion_tokens=completion_tokens,
                total_tokens=total_tokens,
                response_time_ms=response_time_ms,
                success=success,
                user_id=user_id,
                session_id=session_id,
                error_message=error_message
            )
            
            analytics = AnalyticsService()
            await analytics.log_openai_request(request_data)
        except Exception as e:
            # –õ–æ–≥–∏—Ä—É–µ–º –æ—à–∏–±–∫—É, –Ω–æ –Ω–µ –ø—Ä–µ—Ä—ã–≤–∞–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ—Ü–µ—Å—Å
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–∏ OpenAI –∑–∞–ø—Ä–æ—Å–∞: {e}")


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä —Å–µ—Ä–≤–∏—Å–∞ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞  
openai_service = OpenAIService()


async def generate_letter_with_retry(prompt: str, temperature: Optional[float] = None) -> Optional[str]:
    """
    –£–¥–æ–±–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–∏—Å—å–º–∞ —Å –≥–æ—Ç–æ–≤—ã–º –ø—Ä–æ–º–ø—Ç–æ–º
    """
    return await openai_service.generate_personalized_letter(prompt, temperature) 